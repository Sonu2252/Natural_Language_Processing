{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Information_Extraction_NLP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNPz09l+aVyog3f7DtziE31",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sonu2252/Abhi/blob/master/Information_Extraction_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oygofe2sHHi5"
      },
      "outputs": [],
      "source": [
        "    import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install textacy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aEBQI8WzICpz",
        "outputId": "127a89f7-86ed-4579-e169-dd28f6198542"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting textacy\n",
            "  Downloading textacy-0.11.0-py3-none-any.whl (200 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▋                              | 10 kB 19.0 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 20 kB 24.6 MB/s eta 0:00:01\r\u001b[K     |█████                           | 30 kB 30.5 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 40 kB 26.5 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 51 kB 10.3 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 61 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 71 kB 9.6 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 81 kB 10.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 92 kB 11.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 102 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 112 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 122 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 133 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 143 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 153 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 163 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 174 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 184 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 194 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 200 kB 10.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.10.0 in /usr/local/lib/python3.7/dist-packages (from textacy) (2.23.0)\n",
            "Requirement already satisfied: cachetools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from textacy) (4.2.4)\n",
            "Collecting jellyfish>=0.8.0\n",
            "  Downloading jellyfish-0.9.0.tar.gz (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 55.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from textacy) (1.4.1)\n",
            "Requirement already satisfied: tqdm>=4.19.6 in /usr/local/lib/python3.7/dist-packages (from textacy) (4.64.0)\n",
            "Requirement already satisfied: scikit-learn>=0.19.0 in /usr/local/lib/python3.7/dist-packages (from textacy) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.13.0 in /usr/local/lib/python3.7/dist-packages (from textacy) (1.1.0)\n",
            "Collecting cytoolz>=0.10.1\n",
            "  Downloading cytoolz-0.11.2.tar.gz (481 kB)\n",
            "\u001b[K     |████████████████████████████████| 481 kB 61.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.7/dist-packages (from textacy) (1.21.6)\n",
            "Collecting pyphen>=0.10.0\n",
            "  Downloading pyphen-0.12.0-py3-none-any.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 45.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from textacy) (2.6.3)\n",
            "Collecting spacy>=3.0.0\n",
            "  Downloading spacy-3.3.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.2 MB 26.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: toolz>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from cytoolz>=0.10.1->textacy) (0.11.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->textacy) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->textacy) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->textacy) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->textacy) (2.10)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.0->textacy) (3.1.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (1.0.7)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (2.0.6)\n",
            "Collecting typing-extensions<4.0.0.0,>=3.7.4\n",
            "  Downloading typing_extensions-3.10.0.2-py3-none-any.whl (26 kB)\n",
            "Collecting spacy-legacy<3.1.0,>=3.0.9\n",
            "  Downloading spacy_legacy-3.0.9-py2.py3-none-any.whl (20 kB)\n",
            "Collecting typer<0.5.0,>=0.3.0\n",
            "  Downloading typer-0.4.1-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (0.9.1)\n",
            "Collecting langcodes<4.0.0,>=3.2.0\n",
            "  Downloading langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 59.3 MB/s \n",
            "\u001b[?25hCollecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\n",
            "  Downloading pydantic-1.8.2-cp37-cp37m-manylinux2014_x86_64.whl (10.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1 MB 35.4 MB/s \n",
            "\u001b[?25hCollecting thinc<8.1.0,>=8.0.14\n",
            "  Downloading thinc-8.0.15-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (653 kB)\n",
            "\u001b[K     |████████████████████████████████| 653 kB 57.7 MB/s \n",
            "\u001b[?25hCollecting pathy>=0.3.5\n",
            "  Downloading pathy-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 1.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (3.0.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (57.4.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (21.3)\n",
            "Collecting catalogue<2.1.0,>=2.0.6\n",
            "  Downloading catalogue-2.0.7-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (2.11.3)\n",
            "Collecting srsly<3.0.0,>=2.4.3\n",
            "  Downloading srsly-2.4.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (457 kB)\n",
            "\u001b[K     |████████████████████████████████| 457 kB 56.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (0.4.1)\n",
            "Collecting spacy-loggers<2.0.0,>=1.0.0\n",
            "  Downloading spacy_loggers-1.0.2-py3-none-any.whl (7.2 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy>=3.0.0->textacy) (3.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy>=3.0.0->textacy) (3.0.8)\n",
            "Collecting smart-open<6.0.0,>=5.0.0\n",
            "  Downloading smart_open-5.2.1-py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 5.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy>=3.0.0->textacy) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy>=3.0.0->textacy) (2.0.1)\n",
            "Building wheels for collected packages: cytoolz, jellyfish\n",
            "  Building wheel for cytoolz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cytoolz: filename=cytoolz-0.11.2-cp37-cp37m-linux_x86_64.whl size=1230866 sha256=e0cd8b5c270c5701e2cdbe9bfa71eedc2eade639044926050bbf047a598a84b6\n",
            "  Stored in directory: /root/.cache/pip/wheels/38/70/71/ca13ea3d36ccd0b3d0ec7d7a4ca67522048d695b556bba4f59\n",
            "  Building wheel for jellyfish (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jellyfish: filename=jellyfish-0.9.0-cp37-cp37m-linux_x86_64.whl size=73978 sha256=881f181b15c84ac4a54ae006f5fbba045aa3f1f1c8f52836c1fdec5c09f84fc3\n",
            "  Stored in directory: /root/.cache/pip/wheels/fe/99/4e/646ce766df0d070b0ef04db27aa11543e2767fda3075aec31b\n",
            "Successfully built cytoolz jellyfish\n",
            "Installing collected packages: typing-extensions, catalogue, typer, srsly, smart-open, pydantic, thinc, spacy-loggers, spacy-legacy, pathy, langcodes, spacy, pyphen, jellyfish, cytoolz, textacy\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing-extensions 4.2.0\n",
            "    Uninstalling typing-extensions-4.2.0:\n",
            "      Successfully uninstalled typing-extensions-4.2.0\n",
            "  Attempting uninstall: catalogue\n",
            "    Found existing installation: catalogue 1.0.0\n",
            "    Uninstalling catalogue-1.0.0:\n",
            "      Successfully uninstalled catalogue-1.0.0\n",
            "  Attempting uninstall: srsly\n",
            "    Found existing installation: srsly 1.0.5\n",
            "    Uninstalling srsly-1.0.5:\n",
            "      Successfully uninstalled srsly-1.0.5\n",
            "  Attempting uninstall: smart-open\n",
            "    Found existing installation: smart-open 6.0.0\n",
            "    Uninstalling smart-open-6.0.0:\n",
            "      Successfully uninstalled smart-open-6.0.0\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 7.4.0\n",
            "    Uninstalling thinc-7.4.0:\n",
            "      Successfully uninstalled thinc-7.4.0\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 2.2.4\n",
            "    Uninstalling spacy-2.2.4:\n",
            "      Successfully uninstalled spacy-2.2.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\u001b[0m\n",
            "Successfully installed catalogue-2.0.7 cytoolz-0.11.2 jellyfish-0.9.0 langcodes-3.3.0 pathy-0.6.1 pydantic-1.8.2 pyphen-0.12.0 smart-open-5.2.1 spacy-3.3.0 spacy-legacy-3.0.9 spacy-loggers-1.0.2 srsly-2.4.3 textacy-0.11.0 thinc-8.0.15 typer-0.4.1 typing-extensions-3.10.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import textacy"
      ],
      "metadata": {
        "id": "WRoN_aqUH55i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_text = \"Have you ever tried to communicate with someone who didn’t speak your language, and they couldn’t understand you? The classic example of this is when someone goes out to a restaurant in a Foreign country and they think they ordered steak, but when the food shows up, it turns out they actually asked for liver stew.\""
      ],
      "metadata": {
        "id": "-YVR1moAH8zm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "MMbPMbydIAJE",
        "outputId": "0d4bec7f-151d-4b56-c2a0-b92fdbb697ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Have you ever tried to communicate with someone who didn’t speak your language, and they couldn’t understand you? The classic example of this is when someone goes out to a restaurant in a Foreign country and they think they ordered steak, but when the food shows up, it turns out they actually asked for liver stew.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = raw_text.lower()\n"
      ],
      "metadata": {
        "id": "7c0ordrcIPPG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "corpus = re.sub(r'/d+', ' ', corpus)\n",
        "print(corpus)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zuuuVedvolHu",
        "outputId": "1fd8711d-174a-41dd-fbe0-2ba96e6ba8b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "have you ever tried to communicate with someone who didn’t speak your language, and they couldn’t understand you? the classic example of this is when someone goes out to a restaurant in a foreign country and they think they ordered steak, but when the food shows up, it turns out they actually asked for liver stew.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "corpus = corpus.translate(str.maketrans('', '', string.punctuation))"
      ],
      "metadata": {
        "id": "5jY_JEPBo-yi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = ' '.join([token for token in corpus.split()])"
      ],
      "metadata": {
        "id": "vaJ_7JugpJlF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "vJsHHFQ0pRsh",
        "outputId": "9692cf20-d3c3-4e2a-a743-ba26edb1db97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'have you ever tried to communicate with someone who didn’t speak your language and they couldn’t understand you the classic example of this is when someone goes out to a restaurant in a foreign country and they think they ordered steak but when the food shows up it turns out they actually asked for liver stew'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install keybert"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RRX_gIvdpSmB",
        "outputId": "1c286f22-2e94-473c-b851-2483e72051c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keybert\n",
            "  Downloading keybert-0.5.1.tar.gz (19 kB)\n",
            "Collecting sentence-transformers>=0.3.8\n",
            "  Downloading sentence-transformers-2.2.0.tar.gz (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 4.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.22.2 in /usr/local/lib/python3.7/dist-packages (from keybert) (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.7/dist-packages (from keybert) (1.21.6)\n",
            "Collecting rich>=10.4.0\n",
            "  Downloading rich-12.4.0-py3-none-any.whl (231 kB)\n",
            "\u001b[K     |████████████████████████████████| 231 kB 40.9 MB/s \n",
            "\u001b[?25hCollecting typing-extensions<5.0,>=4.0.0\n",
            "  Downloading typing_extensions-4.2.0-py3-none-any.whl (24 kB)\n",
            "Collecting commonmark<0.10.0,>=0.9.0\n",
            "  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[K     |████████████████████████████████| 51 kB 6.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from rich>=10.4.0->keybert) (2.6.1)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22.2->keybert) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22.2->keybert) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22.2->keybert) (3.1.0)\n",
            "Collecting transformers<5.0.0,>=4.6.0\n",
            "  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 50.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence-transformers>=0.3.8->keybert) (4.64.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers>=0.3.8->keybert) (1.11.0+cu113)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence-transformers>=0.3.8->keybert) (0.12.0+cu113)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers>=0.3.8->keybert) (3.2.5)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 40.1 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub\n",
            "  Downloading huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 6.0 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 34.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (2.23.0)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 38.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (3.6.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 49.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (4.11.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (3.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (3.8.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers>=0.3.8->keybert) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (3.0.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (7.1.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence-transformers>=0.3.8->keybert) (7.1.2)\n",
            "Building wheels for collected packages: keybert, sentence-transformers, sacremoses\n",
            "  Building wheel for keybert (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keybert: filename=keybert-0.5.1-py3-none-any.whl size=21332 sha256=77a1a15d3e5183c657c37c836c73a2f6d9e76d21624061124daf4b3e521850c3\n",
            "  Stored in directory: /root/.cache/pip/wheels/8e/95/c5/f5ceed2a9f9e80bc1a706a10a6fb03d726df7a3dd11800a58b\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.0-py3-none-any.whl size=120747 sha256=954e4d3f14669d3f30ecdef83cdf4a06627c5de6017ff4f3237b237836d2b951\n",
            "  Stored in directory: /root/.cache/pip/wheels/83/c0/df/b6873ab7aac3f2465aa9144b6b4c41c4391cfecc027c8b07e7\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=936bd516462098922897603450cf579270332a8cb761d8b92ea95268acc0380f\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
            "Successfully built keybert sentence-transformers sacremoses\n",
            "Installing collected packages: typing-extensions, pyyaml, tokenizers, sacremoses, huggingface-hub, transformers, sentencepiece, commonmark, sentence-transformers, rich, keybert\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing-extensions 3.10.0.2\n",
            "    Uninstalling typing-extensions-3.10.0.2:\n",
            "      Successfully uninstalled typing-extensions-3.10.0.2\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\n",
            "thinc 8.0.15 requires typing-extensions<4.0.0.0,>=3.7.4.1; python_version < \"3.8\", but you have typing-extensions 4.2.0 which is incompatible.\n",
            "spacy 3.3.0 requires typing-extensions<4.0.0.0,>=3.7.4; python_version < \"3.8\", but you have typing-extensions 4.2.0 which is incompatible.\u001b[0m\n",
            "Successfully installed commonmark-0.9.1 huggingface-hub-0.5.1 keybert-0.5.1 pyyaml-6.0 rich-12.4.0 sacremoses-0.0.53 sentence-transformers-2.2.0 sentencepiece-0.1.96 tokenizers-0.12.1 transformers-4.18.0 typing-extensions-4.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keybert import KeyBERT"
      ],
      "metadata": {
        "id": "HwGmnvH3qb5X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "qhjUq_pYq8bH",
        "outputId": "c562bb3c-19bf-4932-f726-7409e1da9c2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Have you ever tried to communicate with someone who didn’t speak your language, and they couldn’t understand you? The classic example of this is when someone goes out to a restaurant in a Foreign country and they think they ordered steak, but when the food shows up, it turns out they actually asked for liver stew.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kw_model = KeyBERT()\n",
        "keywords = kw_model.extract_keywords(raw_text)"
      ],
      "metadata": {
        "id": "UCelkdk_rMnW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#n_gram = 1\n",
        "kw_model.extract_keywords(raw_text, keyphrase_ngram_range=(1, 1), stop_words=None)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJf543U1rYh_",
        "outputId": "444654b8-b265-4b4e-89fa-a488fbd2b80d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('communicate', 0.4743),\n",
              " ('speak', 0.4206),\n",
              " ('language', 0.4046),\n",
              " ('foreign', 0.2674),\n",
              " ('have', 0.2227)]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "HokaaDHcrxBG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Name Entitty Recogniser"
      ],
      "metadata": {
        "id": "Cy7jTPS0xyN-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy"
      ],
      "metadata": {
        "id": "6w2e4GGgx8OH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "metadata": {
        "id": "J5sdwYWxx-O4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_ents(doc):\n",
        "  if doc.ents:\n",
        "    for ent in doc.ents: \n",
        "      print(ent.text+' - '+ent.label_+' - '+str(spacy.explain(ent.label_)))\n",
        "  else:\n",
        "    print(\"No entities found!!!\")"
      ],
      "metadata": {
        "id": "UR-EPzyI0UJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(u\"Hi, How are you?\")\n",
        "show_ents(doc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQLw1Wqy2kaa",
        "outputId": "1949df78-74f8-4330-e09a-38fbfeb5760f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No entities found!!!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc2 = nlp(u\"May I go to New York, next May to see Statue of Liberty?\")\n"
      ],
      "metadata": {
        "id": "uK49KXDp26e6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_ents(doc2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLM0LdxW3HSm",
        "outputId": "9b1da11e-70e7-4c52-960c-08b161d0bb09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New York - GPE - Countries, cities, states\n",
            "next May - DATE - Absolute or relative dates or periods\n",
            "Statue of Liberty - FAC - Buildings, airports, highways, bridges, etc.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc3 = nlp(u\"Can I please have 500 dollars for Microsoft Stocks?\")\n"
      ],
      "metadata": {
        "id": "QgYqy7CV3JWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_ents(doc3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43Afl_Nt3dxT",
        "outputId": "d4518e0f-70ae-4f43-b72d-6d7eb6aa7444"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "500 dollars - MONEY - Monetary values, including unit\n",
            "Microsoft - ORG - Companies, agencies, institutions, etc.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc4 = nlp(u\"Tesla to build a U.K. factory for $6 million\")"
      ],
      "metadata": {
        "id": "RkeNzT6w3hCW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_ents(doc4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QumwM1Tq3vLp",
        "outputId": "fcab6f19-e7a2-4408-82d4-acf7cbbc6417"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "U.K. - GPE - Countries, cities, states\n",
            "$6 million - MONEY - Monetary values, including unit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#To add entities like Tesla in above example\n",
        "from spacy.tokens import Span\n",
        "ORG = doc4.vocab.strings[u\"ORG\"]"
      ],
      "metadata": {
        "id": "hFFzeldB3xrq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ORG"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWSV3oSI4KVL",
        "outputId": "e0c03ce2-0761-4006-bd78-e36706449c4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "383"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_ent = Span(doc4, 0, 1,label=ORG)"
      ],
      "metadata": {
        "id": "FUg2HNE14LXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc4.ents = list(doc4.ents)+[new_ent]"
      ],
      "metadata": {
        "id": "dY9w2zKU4V5Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_ents(doc4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0OWqWOj4kFQ",
        "outputId": "5d0860ef-42ae-47b7-97fe-41fcfb0e48d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tesla - ORG - Companies, agencies, institutions, etc.\n",
            "U.K. - GPE - Countries, cities, states\n",
            "$6 million - MONEY - Monetary values, including unit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "tWI0nVt-4mU8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}